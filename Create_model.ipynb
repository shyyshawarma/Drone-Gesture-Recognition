{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gestures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gesture</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>y16</th>\n",
       "      <th>x17</th>\n",
       "      <th>y17</th>\n",
       "      <th>x18</th>\n",
       "      <th>y18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Up</td>\n",
       "      <td>360.072289</td>\n",
       "      <td>446.489954</td>\n",
       "      <td>305.643253</td>\n",
       "      <td>420.917845</td>\n",
       "      <td>258.756447</td>\n",
       "      <td>347.296000</td>\n",
       "      <td>279.383850</td>\n",
       "      <td>278.214226</td>\n",
       "      <td>322.739868</td>\n",
       "      <td>...</td>\n",
       "      <td>339.012642</td>\n",
       "      <td>348.013716</td>\n",
       "      <td>426.472435</td>\n",
       "      <td>292.254524</td>\n",
       "      <td>400.249748</td>\n",
       "      <td>286.116085</td>\n",
       "      <td>378.542747</td>\n",
       "      <td>344.896746</td>\n",
       "      <td>373.588028</td>\n",
       "      <td>368.872032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up</td>\n",
       "      <td>442.175941</td>\n",
       "      <td>448.529806</td>\n",
       "      <td>390.659294</td>\n",
       "      <td>417.370176</td>\n",
       "      <td>356.007767</td>\n",
       "      <td>341.221189</td>\n",
       "      <td>389.327774</td>\n",
       "      <td>276.759081</td>\n",
       "      <td>433.775406</td>\n",
       "      <td>...</td>\n",
       "      <td>429.147491</td>\n",
       "      <td>347.256317</td>\n",
       "      <td>521.741943</td>\n",
       "      <td>306.899214</td>\n",
       "      <td>510.225182</td>\n",
       "      <td>298.428812</td>\n",
       "      <td>480.816994</td>\n",
       "      <td>351.386690</td>\n",
       "      <td>464.656105</td>\n",
       "      <td>371.861229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Up</td>\n",
       "      <td>529.526978</td>\n",
       "      <td>459.464521</td>\n",
       "      <td>474.327164</td>\n",
       "      <td>422.356768</td>\n",
       "      <td>447.245445</td>\n",
       "      <td>347.327356</td>\n",
       "      <td>490.460205</td>\n",
       "      <td>286.001873</td>\n",
       "      <td>539.601517</td>\n",
       "      <td>...</td>\n",
       "      <td>523.322372</td>\n",
       "      <td>354.476051</td>\n",
       "      <td>611.524811</td>\n",
       "      <td>327.034836</td>\n",
       "      <td>607.524033</td>\n",
       "      <td>308.534460</td>\n",
       "      <td>574.076653</td>\n",
       "      <td>355.189104</td>\n",
       "      <td>553.310852</td>\n",
       "      <td>377.355509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Up</td>\n",
       "      <td>285.250282</td>\n",
       "      <td>447.886362</td>\n",
       "      <td>224.648113</td>\n",
       "      <td>417.484245</td>\n",
       "      <td>174.471798</td>\n",
       "      <td>350.775805</td>\n",
       "      <td>185.150471</td>\n",
       "      <td>288.448906</td>\n",
       "      <td>221.223507</td>\n",
       "      <td>...</td>\n",
       "      <td>254.566631</td>\n",
       "      <td>352.027559</td>\n",
       "      <td>352.056580</td>\n",
       "      <td>291.175032</td>\n",
       "      <td>312.886734</td>\n",
       "      <td>296.159420</td>\n",
       "      <td>289.640751</td>\n",
       "      <td>346.875086</td>\n",
       "      <td>288.816662</td>\n",
       "      <td>368.335390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Up</td>\n",
       "      <td>247.484894</td>\n",
       "      <td>447.473431</td>\n",
       "      <td>179.302368</td>\n",
       "      <td>417.307606</td>\n",
       "      <td>124.952240</td>\n",
       "      <td>351.022224</td>\n",
       "      <td>127.234125</td>\n",
       "      <td>286.537113</td>\n",
       "      <td>162.055264</td>\n",
       "      <td>...</td>\n",
       "      <td>203.752289</td>\n",
       "      <td>352.696838</td>\n",
       "      <td>299.736767</td>\n",
       "      <td>280.795412</td>\n",
       "      <td>252.237377</td>\n",
       "      <td>297.029400</td>\n",
       "      <td>232.533188</td>\n",
       "      <td>349.243383</td>\n",
       "      <td>234.104424</td>\n",
       "      <td>370.457869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gesture          x0          y0          x1          y1          x2  \\\n",
       "0      Up  360.072289  446.489954  305.643253  420.917845  258.756447   \n",
       "1      Up  442.175941  448.529806  390.659294  417.370176  356.007767   \n",
       "2      Up  529.526978  459.464521  474.327164  422.356768  447.245445   \n",
       "3      Up  285.250282  447.886362  224.648113  417.484245  174.471798   \n",
       "4      Up  247.484894  447.473431  179.302368  417.307606  124.952240   \n",
       "\n",
       "           y2          x3          y3          x4  ...         x16  \\\n",
       "0  347.296000  279.383850  278.214226  322.739868  ...  339.012642   \n",
       "1  341.221189  389.327774  276.759081  433.775406  ...  429.147491   \n",
       "2  347.327356  490.460205  286.001873  539.601517  ...  523.322372   \n",
       "3  350.775805  185.150471  288.448906  221.223507  ...  254.566631   \n",
       "4  351.022224  127.234125  286.537113  162.055264  ...  203.752289   \n",
       "\n",
       "          y16         x17         y17         x18         y18         x19  \\\n",
       "0  348.013716  426.472435  292.254524  400.249748  286.116085  378.542747   \n",
       "1  347.256317  521.741943  306.899214  510.225182  298.428812  480.816994   \n",
       "2  354.476051  611.524811  327.034836  607.524033  308.534460  574.076653   \n",
       "3  352.027559  352.056580  291.175032  312.886734  296.159420  289.640751   \n",
       "4  352.696838  299.736767  280.795412  252.237377  297.029400  232.533188   \n",
       "\n",
       "          y19         x20         y20  \n",
       "0  344.896746  373.588028  368.872032  \n",
       "1  351.386690  464.656105  371.861229  \n",
       "2  355.189104  553.310852  377.355509  \n",
       "3  346.875086  288.816662  368.335390  \n",
       "4  349.243383  234.104424  370.457869  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5086, 43)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gesture\n",
       "Down        716\n",
       "Up          712\n",
       "Forward     669\n",
       "Flip        668\n",
       "Left        630\n",
       "Right       614\n",
       "Backward    555\n",
       "Stop        522\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gesture'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gesture']=df['gesture'].map({'Stop':0,'Backward':1,'Forward':2,'Up':3,'Down':4,'Left':5,'Right':6,'Flip':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gesture\n",
       "4    716\n",
       "3    712\n",
       "2    669\n",
       "7    668\n",
       "5    630\n",
       "6    614\n",
       "1    555\n",
       "0    522\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gesture'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.constant(df)\n",
    "tensor_data = tf.random.shuffle(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=tensor_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=tensor_data[:int(m*0.9),1:]\n",
    "train_y=tensor_data[:int(m*0.9),:1]\n",
    "test_X=tensor_data[int(m*0.9):,1:]\n",
    "test_y=tensor_data[int(m*0.9):,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4577, 42), dtype=float64, numpy=\n",
       "array([[574.05902863, 171.62525654, 567.38601685, ..., 108.59870911,\n",
       "        574.30583954, 112.60107994],\n",
       "       [357.12749481, 147.12142467, 314.9263382 , ..., 156.73695087,\n",
       "        289.16688919, 154.60212708],\n",
       "       [387.21885681,  94.48187828, 372.27222443, ..., 197.60231495,\n",
       "        449.48570251, 182.47611523],\n",
       "       ...,\n",
       "       [336.08905792, 435.43622017, 312.60526657, ..., 445.17047882,\n",
       "        268.62913132, 444.3601799 ],\n",
       "       [291.88112259,  43.45589161, 263.56145859, ..., 149.96091843,\n",
       "        332.43038177, 133.91099453],\n",
       "       [420.51612854,  95.69342136, 425.2935791 , ...,  86.62293434,\n",
       "        441.690979  ,  87.78355122]])>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.1814 - loss: 7.6130  \n",
      "Epoch 2/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.3259 - loss: 1.7028\n",
      "Epoch 3/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.4610 - loss: 1.5270\n",
      "Epoch 4/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.4923 - loss: 1.3910\n",
      "Epoch 5/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.6071 - loss: 1.0823\n",
      "Epoch 6/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.6741 - loss: 0.9249\n",
      "Epoch 7/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7069 - loss: 0.8636\n",
      "Epoch 8/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7702 - loss: 0.7067\n",
      "Epoch 9/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8234 - loss: 0.5136\n",
      "Epoch 10/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.8150 - loss: 0.5653\n",
      "Epoch 11/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9166 - loss: 0.2790\n",
      "Epoch 12/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.8914 - loss: 0.3107\n",
      "Epoch 13/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9298 - loss: 0.2227\n",
      "Epoch 14/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9074 - loss: 0.2792\n",
      "Epoch 15/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9484 - loss: 0.1591\n",
      "Epoch 16/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9400 - loss: 0.1790\n",
      "Epoch 17/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.9609 - loss: 0.1404\n",
      "Epoch 18/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9296 - loss: 0.2247\n",
      "Epoch 19/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9347 - loss: 0.2031\n",
      "Epoch 20/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9623 - loss: 0.1220\n",
      "Epoch 21/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.9604 - loss: 0.1287\n",
      "Epoch 22/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9634 - loss: 0.1130\n",
      "Epoch 23/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9644 - loss: 0.1158\n",
      "Epoch 24/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.7463 - loss: 0.9628\n",
      "Epoch 25/100\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9140 - loss: 0.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31e7e7bc0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dense(128,activation='relu'),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(8,activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_X, train_y, epochs=100, callbacks=keras.callbacks.EarlyStopping(monitor='accuracy', patience=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9848 - loss: 0.0620 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06865157932043076, 0.9823182821273804]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
